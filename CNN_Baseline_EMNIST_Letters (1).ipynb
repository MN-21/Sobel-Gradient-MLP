{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MN-21/handwriting-dnn-features/blob/main/CNN_Baseline_EMNIST_Letters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eece91a18db0471ba3c9c5e94e7b2868",
            "4276ef0a0e9845c79810f5e3186d5321",
            "6b232e36045340269a8ea6b1a0f0a980",
            "7203c86de6504f159a86a38a7081b82e",
            "1a1630d4377647d69a9db477d6d90826",
            "bd59228e90c344abb50f6a199f33ce86",
            "66afa6c6d15c423d9c0af9b0dca1a8fe",
            "58b11048e5f4433b8a74f464c0c83232",
            "fd29e3f63a48436fa64f6fb02c2f25dc",
            "e1f7392cf9c346baa205d783b5a1bec8",
            "05d0f36c5d62449c99a57e001c3b9b9f",
            "260e1de81add4b5383140e94e900f26a",
            "f7377deb4fd34f8b9fa42ed698fae27c",
            "73b22f1265234771acb6d2562b6f96e8",
            "78543a6eadc54b6ea5c38608f572b2e9",
            "aa3ed8c31a3042bb80d882cd5ce7be83",
            "e6cb1069ea1640fbb4fffa41a34f95d4",
            "a5918571f0644372928aa11ab96e6c8b",
            "4e8b3d4ba58143e58aa25a1e9bde8070",
            "35efdeb8ae004926a761203da3c9982e",
            "9d0246bd4bbd45789daf6be2503c5751",
            "6496f9cab45e49f7954ce323137b25af",
            "883a52a7a05948a48c5681fb8a4a2f66",
            "a179ee2d232a43d9ad2dded97b848155",
            "c2eee6adf015471eb122e01a49552919",
            "26396973e19d4a17a6ac6a261c3fd0f9",
            "6f0156ab974e47f5a4e1e10cc3332974",
            "786162958278492a9e5daa34d1d7aaff",
            "b24a1b8e06b14a53aaebebbd0225ef5a",
            "01fe3fd118b04f52a921881a88343926",
            "3e180865672e48d08faac1d0081482e6",
            "f2a0a53868dd45d89e85197238b70ce5",
            "84a96c7fdc4d414388f883771b7d1885",
            "2c65faae9eba44d1b67019737fada24d",
            "237c2ba50e29486b82ec29410828ccfb",
            "afc74efd4ea04be98f659970513b808e",
            "931bcbf0c09f4824947b9e49e0190382",
            "7a3aa51772c648eaa06723034d0be64d",
            "e78caaf64b0949a88d929c801fece6d7",
            "3e938e6002464d519e32f261f314f3c5",
            "db5660f8cecb41a9af382e2b283e2c6c",
            "966f7813d9074caba4eec6f1fe976570",
            "4269297bb7644d479576ca0f82a25d93",
            "274dda8748e341069587e45d7a8f8cfc",
            "f4317c4cd36b48c1af04b8c7ef8073e1",
            "2994f37d036d40d2829b6e4e1382ef52",
            "7717062cdc104c488051734c4eeaec94",
            "d604551186064a7fa39bc7e821416ef4",
            "18fd8dfeaf3647a78cceb63094de8dd7",
            "9931c44c7b454a56942b0bab3ed15a18",
            "62a363df9928473dabfc23e622d12473",
            "19f06beaf8c74395894c5067c2cd79ad",
            "e1c516084e1e4b9cbd6f9894650b17c8",
            "c57156088ec048339acf7bc89b634948",
            "4da2123e96604b36aeee3d4563025a4b",
            "34f43d594059470786ae211c945e5c02",
            "7db485740f9f4d4bb59fd631888bec3d",
            "7d5092be022f40d2be562c4c0f383ba4",
            "a8696470998643a78d28fb67285c1d49",
            "90848df58b7e4476ae11262301c9865a",
            "5ff8b9f0bb2b483685ffb21a2f6f569c",
            "d6b99010611b4db8a66d22fa74690563",
            "b92fdc299cbe45aeb0ff5903f6069620",
            "24221ac1cb434f77b6295ef85e7426c9",
            "bbe7715e91294563aecfdd62b4b5a7dd",
            "cb8f28eac4634069b53bdaa6cac749f0",
            "7d84954b50d24652b2f33971eee8c056",
            "b1a8a2b652cc473c84512e42db3a3cb7",
            "9e8db5974e104e04ac9210e3929734da",
            "5616ee116c654b3f86e71e8cbd8b1192",
            "9ee30bd6823e4a2dab61820c0f6827b3",
            "84620a20659645bc9e0a1a3463116dbe",
            "8b0aa99e57e5418f929a83f5efff26d8",
            "2e95269b98804b03a20f8e41e76e5c77",
            "687f8ac70d7e4e88b58209447b217ca7",
            "682cddee0cfc4e9b9cbb8ddc3b6cb49e",
            "34084b41c73c4aacae311440f2ed7611",
            "247bc106418544d7a81cd572a4d02139",
            "33fbbb2fefc0460fbb75ec3f91ad7dc2",
            "c923840b347f48f2af2e7dc80d538ed6",
            "e800757489574bddaef96dd39d048db9",
            "e8b732a3ea1e49c8b36fd6c6c3798cad",
            "7f5796ad73a1439d8c52ef52d15b77d2",
            "0479bda0f4884b9daf582fbd9872bb65",
            "d251ca1f9ee74e0ead6484b27a99cad8",
            "6f405b392c8b4bd587f54bdddfa98c75",
            "599006558cef4434b20bf462a23d21be",
            "9434f8738b54446a97af19676b14950b",
            "9d36b7d6bb4d43e092d800e5d28283ce",
            "feec2a43986b4283bec01ef9b2cd5706",
            "82c1ef4deda744fc9cbffbcfdc8a6613",
            "7d0293c090ee4fd1b87827e5aa66dffd",
            "d31f190ff6314b04bcc708fbe26581e5",
            "76ed514cfd5049929bb572986e3a88f5",
            "f523d19c12df4d59b6b13d6d618ad661",
            "8da3fc1664004fbfbdc768533a9f56d7",
            "3b1dc647e2244073a613abb329e53552",
            "5b24d021fab946c4a0889a3f36a21007",
            "102d506e3fcf4f258cb07c5b3958c8cd"
          ]
        },
        "id": "IQj7F38uRhLY",
        "outputId": "3109a1a1-3040-4660-c5ba-ba949df7acf7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/emnist/letters/3.1.0 has no dataset_info.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/emnist/letters/3.1.0...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eece91a18db0471ba3c9c5e94e7b2868",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "260e1de81add4b5383140e94e900f26a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "883a52a7a05948a48c5681fb8a4a2f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c65faae9eba44d1b67019737fada24d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4317c4cd36b48c1af04b8c7ef8073e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34f43d594059470786ae211c945e5c02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d84954b50d24652b2f33971eee8c056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/emnist/letters/incomplete.GIPBXY_3.1.0/emnist-train.tfrecord*...:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "247bc106418544d7a81cd572a4d02139",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d36b7d6bb4d43e092d800e5d28283ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/emnist/letters/incomplete.GIPBXY_3.1.0/emnist-test.tfrecord*...:   0%|    …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset emnist downloaded and prepared to /root/tensorflow_datasets/emnist/letters/3.1.0. Subsequent calls will reuse this data.\n",
            "Epoch 1/50\n",
            "648/648 - 166s - 256ms/step - accuracy: 0.7250 - loss: 0.9316 - val_accuracy: 0.7014 - val_loss: 0.9005 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "648/648 - 199s - 307ms/step - accuracy: 0.8396 - loss: 0.5066 - val_accuracy: 0.9056 - val_loss: 0.2988 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "648/648 - 154s - 237ms/step - accuracy: 0.8635 - loss: 0.4241 - val_accuracy: 0.9012 - val_loss: 0.2991 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "648/648 - 158s - 244ms/step - accuracy: 0.8792 - loss: 0.3744 - val_accuracy: 0.9123 - val_loss: 0.2642 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "648/648 - 154s - 237ms/step - accuracy: 0.8897 - loss: 0.3383 - val_accuracy: 0.9225 - val_loss: 0.2303 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "648/648 - 158s - 244ms/step - accuracy: 0.8977 - loss: 0.3163 - val_accuracy: 0.9302 - val_loss: 0.2115 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "648/648 - 201s - 310ms/step - accuracy: 0.9017 - loss: 0.2990 - val_accuracy: 0.9295 - val_loss: 0.2124 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "648/648 - 198s - 306ms/step - accuracy: 0.9051 - loss: 0.2874 - val_accuracy: 0.9331 - val_loss: 0.2010 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "648/648 - 155s - 239ms/step - accuracy: 0.9080 - loss: 0.2768 - val_accuracy: 0.9355 - val_loss: 0.1941 - learning_rate: 1.0000e-03\n",
            "Epoch 10/50\n",
            "648/648 - 199s - 307ms/step - accuracy: 0.9118 - loss: 0.2652 - val_accuracy: 0.9392 - val_loss: 0.1879 - learning_rate: 1.0000e-03\n",
            "Epoch 11/50\n",
            "648/648 - 150s - 231ms/step - accuracy: 0.9139 - loss: 0.2542 - val_accuracy: 0.9375 - val_loss: 0.1871 - learning_rate: 1.0000e-03\n",
            "Epoch 12/50\n",
            "648/648 - 147s - 227ms/step - accuracy: 0.9154 - loss: 0.2504 - val_accuracy: 0.9386 - val_loss: 0.1822 - learning_rate: 1.0000e-03\n",
            "Epoch 13/50\n",
            "648/648 - 155s - 239ms/step - accuracy: 0.9175 - loss: 0.2465 - val_accuracy: 0.9416 - val_loss: 0.1791 - learning_rate: 1.0000e-03\n",
            "Epoch 14/50\n",
            "648/648 - 151s - 233ms/step - accuracy: 0.9198 - loss: 0.2350 - val_accuracy: 0.9386 - val_loss: 0.1862 - learning_rate: 1.0000e-03\n",
            "Epoch 15/50\n",
            "648/648 - 147s - 227ms/step - accuracy: 0.9211 - loss: 0.2337 - val_accuracy: 0.9389 - val_loss: 0.1835 - learning_rate: 1.0000e-03\n",
            "Epoch 16/50\n",
            "648/648 - 209s - 322ms/step - accuracy: 0.9215 - loss: 0.2253 - val_accuracy: 0.9413 - val_loss: 0.1768 - learning_rate: 1.0000e-03\n",
            "Epoch 17/50\n",
            "648/648 - 145s - 224ms/step - accuracy: 0.9242 - loss: 0.2217 - val_accuracy: 0.9424 - val_loss: 0.1737 - learning_rate: 1.0000e-03\n",
            "Epoch 18/50\n",
            "648/648 - 149s - 230ms/step - accuracy: 0.9248 - loss: 0.2178 - val_accuracy: 0.9398 - val_loss: 0.1819 - learning_rate: 1.0000e-03\n",
            "Epoch 19/50\n",
            "648/648 - 151s - 233ms/step - accuracy: 0.9254 - loss: 0.2140 - val_accuracy: 0.9400 - val_loss: 0.1802 - learning_rate: 1.0000e-03\n",
            "Epoch 20/50\n",
            "648/648 - 153s - 236ms/step - accuracy: 0.9268 - loss: 0.2121 - val_accuracy: 0.9439 - val_loss: 0.1715 - learning_rate: 1.0000e-03\n",
            "Epoch 21/50\n",
            "648/648 - 155s - 239ms/step - accuracy: 0.9275 - loss: 0.2083 - val_accuracy: 0.9413 - val_loss: 0.1764 - learning_rate: 1.0000e-03\n",
            "Epoch 22/50\n",
            "648/648 - 157s - 242ms/step - accuracy: 0.9284 - loss: 0.2040 - val_accuracy: 0.9423 - val_loss: 0.1769 - learning_rate: 1.0000e-03\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "648/648 - 157s - 242ms/step - accuracy: 0.9298 - loss: 0.2016 - val_accuracy: 0.9415 - val_loss: 0.1760 - learning_rate: 1.0000e-03\n",
            "Epoch 24/50\n",
            "648/648 - 154s - 238ms/step - accuracy: 0.9323 - loss: 0.1906 - val_accuracy: 0.9438 - val_loss: 0.1697 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "648/648 - 156s - 240ms/step - accuracy: 0.9349 - loss: 0.1846 - val_accuracy: 0.9447 - val_loss: 0.1668 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "648/648 - 200s - 308ms/step - accuracy: 0.9355 - loss: 0.1814 - val_accuracy: 0.9450 - val_loss: 0.1646 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "648/648 - 205s - 317ms/step - accuracy: 0.9366 - loss: 0.1812 - val_accuracy: 0.9447 - val_loss: 0.1630 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "648/648 - 154s - 238ms/step - accuracy: 0.9349 - loss: 0.1790 - val_accuracy: 0.9452 - val_loss: 0.1660 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "648/648 - 202s - 312ms/step - accuracy: 0.9373 - loss: 0.1803 - val_accuracy: 0.9458 - val_loss: 0.1652 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "648/648 - 152s - 234ms/step - accuracy: 0.9369 - loss: 0.1771 - val_accuracy: 0.9444 - val_loss: 0.1652 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "648/648 - 155s - 239ms/step - accuracy: 0.9393 - loss: 0.1700 - val_accuracy: 0.9454 - val_loss: 0.1655 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "648/648 - 155s - 239ms/step - accuracy: 0.9392 - loss: 0.1671 - val_accuracy: 0.9451 - val_loss: 0.1639 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "648/648 - 151s - 234ms/step - accuracy: 0.9407 - loss: 0.1651 - val_accuracy: 0.9458 - val_loss: 0.1627 - learning_rate: 2.5000e-04\n",
            "Epoch 34/50\n",
            "648/648 - 156s - 240ms/step - accuracy: 0.9390 - loss: 0.1669 - val_accuracy: 0.9448 - val_loss: 0.1636 - learning_rate: 2.5000e-04\n",
            "Epoch 34: early stopping\n",
            "Restoring model weights from the end of the best epoch: 29.\n",
            "162/162 - 8s - 50ms/step - accuracy: 0.9458 - loss: 0.1652\n",
            "\n",
            "Final Test Accuracy : 94.58%\n",
            "Training Time       : 5606.3s over 34 epochs\n",
            "Inference Time      : 10.2s on 20720 samples\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install --quiet tensorflow_datasets opencv-python tqdm\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, callbacks, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load EMNIST Letters from TensorFlow Datasets\n",
        "(ds_all, ds_info) = tfds.load(\n",
        "    'emnist/letters',\n",
        "    split='train+test',\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")  # Combined train+test for custom split\n",
        "\n",
        "# 2. Convert tf.data to NumPy arrays for stratified split\n",
        "images, labels = [], []\n",
        "for img, lbl in tfds.as_numpy(ds_all):\n",
        "    images.append(img)      # shape (28,28,1)\n",
        "    labels.append(lbl - 1)  # shift 1–26 → 0–25\n",
        "images = np.stack(images).astype(np.float32) / 255.0  # normalize to [0,1]\n",
        "labels = np.array(labels, dtype=int)\n",
        "\n",
        "# 3. Stratified 80/20 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels,\n",
        "    train_size=0.8, test_size=0.2,\n",
        "    stratify=labels, random_state=42\n",
        ")  # preserves class balance\n",
        "\n",
        "# 4. Build tf.data pipelines\n",
        "BATCH_SIZE = 128\n",
        "AUTOTUNE   = tf.data.AUTOTUNE\n",
        "\n",
        "def make_ds(X, y, shuffle=False):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(10_000)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = make_ds(X_train, y_train, shuffle=True)\n",
        "test_ds  = make_ds(X_test,  y_test)\n",
        "\n",
        "# 5. Define the CNN with BatchNorm & Dropout\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(28,28,1)),\n",
        "    layers.Conv2D(32, 3, padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, 3, padding='same'), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.MaxPool2D(),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. Callbacks: EarlyStopping and ReduceLROnPlateau\n",
        "es_cb = callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")  # stops when validation stops improving\n",
        "\n",
        "rlr_cb = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")  # reduces LR on plateau\n",
        "\n",
        "# 7. Train for up to 50 epochs\n",
        "t0 = time.time()\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[es_cb, rlr_cb],\n",
        "    verbose=2\n",
        ")\n",
        "train_time = time.time() - t0\n",
        "\n",
        "# 8. Evaluate on test set\n",
        "t1 = time.time()\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
        "infer_time = time.time() - t1\n",
        "\n",
        "# 9. Report\n",
        "print(f\"\\nFinal Test Accuracy : {test_acc*100:.2f}%\")\n",
        "print(f\"Training Time       : {train_time:.1f}s over {len(history.history['loss'])} epochs\")\n",
        "print(f\"Inference Time      : {infer_time:.1f}s on {len(X_test)} samples\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}