{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MN-21/handwriting-dnn-features/blob/main/Sobel_Gradient_pipeline_EMNIST_Letters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "119d839b0a96419e9a2af6fb2158dc26",
            "3cbe823a5c4144cab329dc2aa464ea58",
            "865c1a15e9c14fc59497ce8d3c774db8",
            "a20d087d369e41a08ce5d287f1e50d81",
            "6f39a31a540543ab8ed8d98cb5fccce8",
            "864af579c63d4ed3b4cbb08d9ce766fd",
            "1ad2e7153c2c4491aece58d0585d1e35",
            "e59fbd20187d4b3eaac29a34571856de",
            "1daa15a20b2d43de82afe3332fa8f3dd",
            "611f1f80f2c946a6b1a2221e27b7c5e3",
            "eeed5a7f0b0a46e0aeac8c21b647210b",
            "d90cfb05cee542f49a25b0e7cc91445a",
            "fb6b9cc3951745cfb572e0d53fb71b88",
            "3daf8fe3009e4a8ead8ed3c1bbebd6dd",
            "abf4494e682647efb3fb75815cd7533e",
            "8c502506be1c466e891bfcb04c18a19a",
            "40c3deb7ea264cf8b26c90a36a63ece0",
            "5704e498d5024f128cf3831317848e26",
            "b35546506d9a4b7c8fe85c86c4800d1b",
            "0841b45c8f234a0d868ee9179d3cd79e",
            "fb402bbc914b4951ab20a2b9fa9a5e37",
            "e229dab90c5e433780a08c293b63df7d",
            "4da30d73a9004c51a88ea8e21b9cbb24",
            "8a1318356c114332b1e1446ec155fd6a",
            "7089e5d928a64c1aae6901ee04109ae5",
            "7c8ee8fd18f347a9a9456637e262ebe9",
            "fb33bc6338d54d6f8e7d37348e21f02e",
            "656d77867f6f4c4a81cd6859ac3f7fd6",
            "4085825b334a45de8b1a0f443a6785a9",
            "ed19918229834463ad53aeeabb4218bd",
            "04c2c3a5c87d4c30aba22bf8cfef9008",
            "4f84925b905c49f29c99b6e9cb0bbe30",
            "f513dc6baa9d4580900c5b05fe233db4",
            "49a3614a0c0848e0924eb5bfd4e0b85c",
            "42df0ddd155c4978bf51195749d2f450",
            "99888912dcf84f4098a92ed4b7eada81",
            "fa54c2259a3444dba2fadc7d2b1f4dd1",
            "b5f2d51821474e69b0673207e9f609ad",
            "12995c05e9994b54b3f4e315ce1c7e0d",
            "1e5dea14328e49a2bb434b7e57fa9967",
            "7e6f7d94a2ce47cb838a96dd00192358",
            "4054cd48d98d478592bec5520c59f93c",
            "000937ec9c66422eba7c9697671b16c0",
            "5893fe105070430c89c6e49bf32ab9b7",
            "5fa6f221a5ff4405a377c73c6da20d08",
            "67d36ab372294311ba63a7c23c7e640e",
            "4e0ebaad74a048ab81ed31f7cfc3c9df",
            "5c10b53decb5465b98531bbad92b41ff",
            "e7b9ae6c879046538777bfac55c4bd44",
            "b3797da0caab4117b5e29cf1759624ae",
            "13e9ccdc4a3c4f75aae58d0c5586fca3",
            "057d3953e35b4228bda650db5c3ec497",
            "9c169eea0f79480789fc110a88ac611d",
            "380f9746f2564a978ab55b4c399ff008",
            "086b04b884a84351967003343f85528a",
            "1c652ed57ec24e03871eb350e420bf90",
            "63c09a9da66c40d49b5233fad796cfc4",
            "246d919207174bccb60071c3b779d490",
            "db05d552bd45430a9b5e0465fc6e9f0f",
            "ec5f287f14994a85a3340d2581f5d30f",
            "76cccfed42a3413e8075534277e1a696",
            "d11c33baca624b099198a0412c4148bc",
            "885e3784504046679d1c8724082a7099",
            "8e7e970d15f846109d092c5c404833a9",
            "a4e6296e464b48dc8c522c7eb93a5edf",
            "f4393b3673e546168b51f13cc40ee627",
            "89dc4b8196414d9a821c17e2e14f8f93",
            "f803d3ea7ae34839973b3731fb069a55",
            "8f1451a0bbb14812a31f641e35c050c1",
            "36b043f3787b493e9e1dc11b959a26e7",
            "45e3b00a044845159b42c9384b084726",
            "8a50cde0410c47aa94509f05ea38d72a",
            "8bb8bcc577284929b8e7f01bd9c8cdd2",
            "0bea1257060345d48a18fab02c3ff27f",
            "cbcd29446b0041518bdf7f2b7745810f",
            "2dd2f78698d64ba6a3cfaf2ce8de3b2a",
            "ba74cf816879486db32c19835f0c362b",
            "dbe638c459cf41e29c33c392340d6508",
            "5fa897e2b5ac48db9364dc791601ab04",
            "299c92276b264fa5bd27ffa3ff60744f",
            "2162dc0e05ba4f74b396a65a08450121",
            "312dd9ab8e14462ab48c3c402b2c65c2",
            "fea983fa8a454f7997cc4ae282238d22",
            "ba07dffeadfa450dbd2427ab5d887e9a",
            "3b0d0f448ca94c13abff46d91e999b5c",
            "254e9a3ba5954c79bd8800bb47d97824",
            "a00361c895fb43a5887db9bc2b93becc",
            "89d5a4c4251e452cb221c5e657ab11f0",
            "4307d6a9633b42608a095ccb610e3245",
            "e1fa7618d5f449448919da8f2ac10bcd",
            "67d5ef7eac5548578650dfdc6e33133c",
            "bcf95d7ff8284f4ebfe06f51f660a3dd",
            "1a68ae2bd5b34798a0928355fd209b9f",
            "21ba1ff69ee546e1a73230cf8d2a3498",
            "c574a5111c034fffb49bd9436cea0691",
            "ffcc8b92e63c41dcbbe29c2a25f33529",
            "ef025529726f4340a3bad23d4bf777fc",
            "d6a926b8869b4c218c463205b4f49c8e",
            "c2183ca0cf03470da8b082c3a0f5772f"
          ]
        },
        "id": "4IO4b-ws34hc",
        "outputId": "5940abce-51ec-4243-95d3-7266fa291b89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/emnist/letters/3.1.0 has no dataset_info.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/emnist/letters/3.1.0...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "119d839b0a96419e9a2af6fb2158dc26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d90cfb05cee542f49a25b0e7cc91445a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4da30d73a9004c51a88ea8e21b9cbb24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a3614a0c0848e0924eb5bfd4e0b85c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fa6f221a5ff4405a377c73c6da20d08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c652ed57ec24e03871eb350e420bf90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89dc4b8196414d9a821c17e2e14f8f93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/emnist/letters/incomplete.3ID7MG_3.1.0/emnist-train.tfrecord*...:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe638c459cf41e29c33c392340d6508",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4307d6a9633b42608a095ccb610e3245",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/emnist/letters/incomplete.3ID7MG_3.1.0/emnist-test.tfrecord*...:   0%|    …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset emnist downloaded and prepared to /root/tensorflow_datasets/emnist/letters/3.1.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing gradients: 100%|██████████| 82880/82880 [00:05<00:00, 14648.86it/s]\n",
            "Computing gradients: 100%|██████████| 20720/20720 [00:01<00:00, 18674.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "583/583 - 37s - 63ms/step - accuracy: 0.6411 - loss: 1.1937 - val_accuracy: 0.3855 - val_loss: 2.1973 - learning_rate: 1.0000e-03\n",
            "Epoch 2/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.7874 - loss: 0.6786 - val_accuracy: 0.6374 - val_loss: 1.0650 - learning_rate: 1.0000e-03\n",
            "Epoch 3/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.8221 - loss: 0.5573 - val_accuracy: 0.5125 - val_loss: 1.6976 - learning_rate: 1.0000e-03\n",
            "Epoch 4/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.8397 - loss: 0.4926 - val_accuracy: 0.6883 - val_loss: 1.0162 - learning_rate: 1.0000e-03\n",
            "Epoch 5/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.8541 - loss: 0.4446 - val_accuracy: 0.7506 - val_loss: 0.8011 - learning_rate: 1.0000e-03\n",
            "Epoch 6/50\n",
            "583/583 - 42s - 73ms/step - accuracy: 0.8654 - loss: 0.4100 - val_accuracy: 0.7788 - val_loss: 0.6734 - learning_rate: 1.0000e-03\n",
            "Epoch 7/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.8713 - loss: 0.3888 - val_accuracy: 0.8000 - val_loss: 0.5940 - learning_rate: 1.0000e-03\n",
            "Epoch 8/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.8793 - loss: 0.3617 - val_accuracy: 0.6979 - val_loss: 0.9974 - learning_rate: 1.0000e-03\n",
            "Epoch 9/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.8849 - loss: 0.3498 - val_accuracy: 0.7161 - val_loss: 0.9674 - learning_rate: 1.0000e-03\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "583/583 - 43s - 74ms/step - accuracy: 0.8882 - loss: 0.3303 - val_accuracy: 0.6181 - val_loss: 1.4934 - learning_rate: 1.0000e-03\n",
            "Epoch 11/50\n",
            "583/583 - 33s - 56ms/step - accuracy: 0.9005 - loss: 0.2937 - val_accuracy: 0.8936 - val_loss: 0.3326 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.9069 - loss: 0.2713 - val_accuracy: 0.8820 - val_loss: 0.3572 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.9097 - loss: 0.2628 - val_accuracy: 0.8989 - val_loss: 0.3065 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.9122 - loss: 0.2539 - val_accuracy: 0.9058 - val_loss: 0.2878 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "583/583 - 42s - 73ms/step - accuracy: 0.9144 - loss: 0.2478 - val_accuracy: 0.9071 - val_loss: 0.2814 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.9150 - loss: 0.2441 - val_accuracy: 0.9019 - val_loss: 0.3039 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.9177 - loss: 0.2362 - val_accuracy: 0.8962 - val_loss: 0.3114 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "583/583 - 32s - 55ms/step - accuracy: 0.9188 - loss: 0.2319 - val_accuracy: 0.8999 - val_loss: 0.3024 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "583/583 - 33s - 57ms/step - accuracy: 0.9238 - loss: 0.2165 - val_accuracy: 0.9190 - val_loss: 0.2384 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "583/583 - 32s - 55ms/step - accuracy: 0.9274 - loss: 0.2044 - val_accuracy: 0.9187 - val_loss: 0.2395 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "583/583 - 42s - 72ms/step - accuracy: 0.9278 - loss: 0.2023 - val_accuracy: 0.9213 - val_loss: 0.2324 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.9303 - loss: 0.1964 - val_accuracy: 0.9190 - val_loss: 0.2454 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "583/583 - 41s - 71ms/step - accuracy: 0.9300 - loss: 0.1957 - val_accuracy: 0.9208 - val_loss: 0.2322 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "583/583 - 41s - 70ms/step - accuracy: 0.9310 - loss: 0.1897 - val_accuracy: 0.9170 - val_loss: 0.2520 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "583/583 - 40s - 69ms/step - accuracy: 0.9315 - loss: 0.1882 - val_accuracy: 0.9207 - val_loss: 0.2430 - learning_rate: 2.5000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "648/648 - 6s - 9ms/step - accuracy: 0.9200 - loss: 0.2445\n",
            "\n",
            "EMNIST Letters Sobel-Gradient MLP\n",
            "Test Accuracy   : 92.00%\n",
            "Training Time   : 986.8s\n",
            "Inference Time  : 10.5s for 20720 samples\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install --quiet tensorflow tensorflow-datasets opencv-python scikit-learn tqdm\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Sobel feature extractor (full-image gradients)\n",
        "def compute_gradients(images):\n",
        "    \"\"\"\n",
        "    Given a NumPy array of shape (N,28,28), returns\n",
        "    an array of shape (N, 2, 28, 28) containing normalized gx, gy.\n",
        "    \"\"\"\n",
        "    N = images.shape[0]\n",
        "    grads = np.zeros((N, 2, 28, 28), dtype=np.float32)\n",
        "    for i, img in enumerate(tqdm(images, desc=\"Computing gradients\")):\n",
        "        gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
        "        # normalize each to [0,1]\n",
        "        gx = (gx - gx.min()) / (gx.max() - gx.min() + 1e-8)\n",
        "        gy = (gy - gy.min()) / (gy.max() - gy.min() + 1e-8)\n",
        "        grads[i,0] = gx\n",
        "        grads[i,1] = gy\n",
        "    return grads\n",
        "\n",
        "# 2. Load EMNIST Letters via TFDS\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'emnist/letters',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# 3. Convert to NumPy arrays\n",
        "all_images = []\n",
        "all_labels = []\n",
        "for img, lbl in tfds.as_numpy(ds_train.concatenate(ds_test)):\n",
        "    all_images.append(img.squeeze())        # shape (28,28)\n",
        "    all_labels.append(int(lbl) - 1)         # shift labels 1–26 → 0–25\n",
        "all_images = np.stack(all_images)           # (145600,28,28)\n",
        "all_labels = np.array(all_labels, dtype=int)\n",
        "\n",
        "# 4. Stratified 80/20 train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    all_images, all_labels,\n",
        "    train_size=0.8,\n",
        "    stratify=all_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 5. Compute Sobel gradient features\n",
        "grad_train = compute_gradients(X_train)\n",
        "grad_test  = compute_gradients(X_test)\n",
        "\n",
        "# 6. Flatten to feature vectors (2*28*28 = 1568 dims)\n",
        "X_train_feat = grad_train.reshape(-1, 2*28*28)\n",
        "X_test_feat  = grad_test.reshape(-1, 2*28*28)\n",
        "\n",
        "# 7. Build MLP model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(2*28*28,)),\n",
        "    layers.Dense(1024), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(512), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Dense(256), layers.BatchNormalization(), layers.Activation('relu'),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 8. Callbacks\n",
        "es = callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy', patience=4,\n",
        "    restore_best_weights=True, verbose=1\n",
        ")\n",
        "rlr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5,\n",
        "    patience=3, min_lr=1e-6, verbose=1\n",
        ")\n",
        "\n",
        "# 9. Train\n",
        "t0 = time.time()\n",
        "history = model.fit(\n",
        "    X_train_feat, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    callbacks=[es, rlr],\n",
        "    verbose=2\n",
        ")\n",
        "train_time = time.time() - t0\n",
        "\n",
        "# 10. Evaluate\n",
        "t1 = time.time()\n",
        "test_loss, test_acc = model.evaluate(X_test_feat, y_test, verbose=2)\n",
        "infer_time = time.time() - t1\n",
        "\n",
        "# 11. Report\n",
        "print(f\"\\nEMNIST Letters Sobel-Gradient MLP\")\n",
        "print(f\"Test Accuracy   : {test_acc*100:.2f}%\")\n",
        "print(f\"Training Time   : {train_time:.1f}s\")\n",
        "print(f\"Inference Time  : {infer_time:.1f}s for {X_test_feat.shape[0]} samples\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}